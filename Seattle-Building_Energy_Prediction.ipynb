{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2192524,"sourceType":"datasetVersion","datasetId":1228273}],"dockerImageVersionId":30066,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport math\n%matplotlib inline\n\nfrom matplotlib.collections import LineCollection\nfrom sklearn import decomposition\nfrom sklearn import preprocessing\nfrom sklearn import datasets, linear_model\nfrom IPython.display import display\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-06T23:58:03.344326Z","iopub.execute_input":"2022-07-06T23:58:03.344964Z","iopub.status.idle":"2022-07-06T23:58:04.930196Z","shell.execute_reply.started":"2022-07-06T23:58:03.344856Z","shell.execute_reply":"2022-07-06T23:58:04.928843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dans ce notebook, on se propose d'entrainer 4 modèle pour nos 2 target\n# le travail se décompose comme suit:\n\n# A. Target = SiteEnergyuse\n    # A.1 sans energystarscore\n    # A.2 avec energystarscore\n    \n# B. Target = Emissions CO2\n    # B.1 sans energystarscore\n    # B.2 avec energystarscore\n\n# Puis on suit ces quelques etapes pour étudier A1.A2,B1,B2:\n\n    # 1. Préapration du dataset: \n        # 1.a Séparation de X,y\n        # 1.b Création d'une' pipeline avec transformation (prise en compte ou non de l'energystarscore avec drop des N.A >> réduction du dataset)\n        \n    # 2. Création d'une baseline de régression (Dummy)\n    \n    # 3. Entrainement des modèles : avec paramètre par défaut puis en utilisant gridsearch en ajustant les params\n        # 3.a Elastic Net\n        # 3.b Random Forest\n        # 3.c Supervised Vector Machine\n        # 3.d Gradient Boost\n        \n    # 4. Tableau récapitulatif des scores de chaque modèle avc ses meilleurs paramètres\n    \n    # 5. Choix du meilleur modèle\n    \n    # 6. Barplot des 20 top features du meilleur modèle\n","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:04.932048Z","iopub.execute_input":"2022-07-06T23:58:04.932360Z","iopub.status.idle":"2022-07-06T23:58:04.937435Z","shell.execute_reply.started":"2022-07-06T23:58:04.932331Z","shell.execute_reply":"2022-07-06T23:58:04.936352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/datap3/data_p3.csv\", sep=',',low_memory=False)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:04.939215Z","iopub.execute_input":"2022-07-06T23:58:04.939584Z","iopub.status.idle":"2022-07-06T23:58:04.988747Z","shell.execute_reply.started":"2022-07-06T23:58:04.939552Z","shell.execute_reply":"2022-07-06T23:58:04.987798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sauvegarde séparée du energy star score\n\nenergy_star_score = data['ENERGYSTARScore']\ndata.drop('ENERGYSTARScore', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:04.989970Z","iopub.execute_input":"2022-07-06T23:58:04.990564Z","iopub.status.idle":"2022-07-06T23:58:05.007784Z","shell.execute_reply.started":"2022-07-06T23:58:04.990530Z","shell.execute_reply":"2022-07-06T23:58:05.006844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.011337Z","iopub.execute_input":"2022-07-06T23:58:05.011987Z","iopub.status.idle":"2022-07-06T23:58:05.043408Z","shell.execute_reply.started":"2022-07-06T23:58:05.011946Z","shell.execute_reply":"2022-07-06T23:58:05.042627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET = 'log_SiteEnergyUseWN(kBtu)'","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.045695Z","iopub.execute_input":"2022-07-06T23:58:05.046189Z","iopub.status.idle":"2022-07-06T23:58:05.050290Z","shell.execute_reply.started":"2022-07-06T23:58:05.046136Z","shell.execute_reply":"2022-07-06T23:58:05.049247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Préapration du dataset: Séparation de X,y, création de pipeline avec transformation\n\ny = data[TARGET]\nX = data.copy().drop(['log_GHGEmissions(MetricTonsCO2e)','log_SiteEnergyUseWN(kBtu)'], axis=1)\n\nprint(data.shape)\n\n# Séparation et préparation des données\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n\nnumeric_features = ['YearBuilt','log_PropertyGFATotal', 'log_LargestPropertyUseTypeGFA',\n                    'log_largest/total', 'log_PropertyGFABuilding(s)','log_PropertyGFAParking']\n\n\"\"\"numeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(missing_values=np.nan,strategy='mean')),\n    ('scaler', StandardScaler())])\"\"\"\n    \nnumeric_transformer = StandardScaler()\n\ncategorical_features = ['Neighborhood','LargestPropertyUseType']\n\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\n\nprint(\"matrice X_train:\", X_train.shape)\nprint(\"matrice y_train:\", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.051752Z","iopub.execute_input":"2022-07-06T23:58:05.052423Z","iopub.status.idle":"2022-07-06T23:58:05.069178Z","shell.execute_reply.started":"2022-07-06T23:58:05.052351Z","shell.execute_reply":"2022-07-06T23:58:05.067881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Création d'une baseline de régression\n\ndef baseline():\n    \n    dummy = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('regressor', DummyRegressor())])\n    \n    print('--------------------------------')\n    print(\"* Dummy\")\n    print('***')\n    print(\"R2\")\n    print(cross_val_score(dummy,X_train, y_train, cv=5, scoring = \"r2\"))\n    print('***')\n    print(\"-Mse\")\n    print(cross_val_score(dummy,X_train, y_train, cv=5, scoring = \"neg_mean_squared_error\"))\n    print('--------------------------------')\n    \n    mean = (cross_val_score(dummy,X_train, y_train, cv=5, scoring = \"r2\")).mean()\n    new_row = {'Modele':'Dummy','Score' : mean }\n    \n    return new_row","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.070875Z","iopub.execute_input":"2022-07-06T23:58:05.071538Z","iopub.status.idle":"2022-07-06T23:58:05.085283Z","shell.execute_reply.started":"2022-07-06T23:58:05.071489Z","shell.execute_reply":"2022-07-06T23:58:05.084254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apres un premier test avec la regréssion linéaire, ridge, lasso et treeregression, on se propose d'étudier le cas d'Elastic Net, Random forest qui sont des cas géneraux\n\ndef elastic_net():\n    \n    # 1. Elastic net\n\n    elastic_net = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('regressor', ElasticNet())])\n\n    print('--------------------------------')\n    print(\"1. Elastic net\")\n    print('***')\n    print(\"R2\")\n    print(cross_val_score(elastic_net,X_train, y_train, cv=5, scoring = \"r2\" ))\n    print('***')\n    print(\"-Mse\")\n    print(cross_val_score(elastic_net,X_train, y_train, cv=5, scoring = \"neg_mean_squared_error\"))\n    print('--------------------------------\\n')\n\n\n    alphas = [0.001, 0.01, 0.1, 1, 10]\n\n    l1_ratio = [0.001,0.5,1]\n\n    parameters = { \n                \"regressor__alpha\": alphas,  ##alpha, coef qui multiplie le terme de pénalité\n                \"regressor__max_iter\":[5000],\n                \"regressor__l1_ratio\": l1_ratio # L1 ratio , =1 équivaut à un Lasso, 0 à un Ridge\n                 } \n\n\n\n    NetCV = GridSearchCV(estimator = elastic_net, \n                          param_grid = parameters,\n                          scoring = 'r2',\n                          cv=5,\n                          verbose=0,\n                         return_train_score = True\n                         )\n\n    NetCV.fit(X_train, y_train)\n\n    result = pd.DataFrame(NetCV.cv_results_)\n    display(result)\n\n    new_row = {'Modele':'Regression Elastic net','Score' : [result[result['rank_test_score']==1]['mean_test_score']]}\n    \n    print(NetCV.best_params_)\n    print('**********')\n    print(NetCV.best_estimator_['regressor'].coef_)\n    \n    return new_row","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.086851Z","iopub.execute_input":"2022-07-06T23:58:05.087530Z","iopub.status.idle":"2022-07-06T23:58:05.100849Z","shell.execute_reply.started":"2022-07-06T23:58:05.087480Z","shell.execute_reply":"2022-07-06T23:58:05.099864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Random Forest Regressor\n\ndef random_forest():\n\n    forest = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('regressor', RandomForestRegressor())])\n\n    print('--------------------------------')\n    print(\"2. Random Forest Regressor\")\n    print('***')\n    print(\"R2\")\n    print(cross_val_score(forest,X_train, y_train, cv=5, scoring = \"r2\" ))\n    print('***')\n    print(\"-Mse\")\n    print(cross_val_score(forest,X_train, y_train, cv=5, scoring = \"neg_mean_squared_error\"))\n    print('--------------------------------\\n')\n\n    parameters = {\n                #'min_samples_leaf' : [1,10,100], #nombre de feuilles minimales dans un noeud\n                #'min_samples_split'\n                #'regressor__max_features': ['auto', 'sqrt', 'log2'], #nombre de features observées pour chaque arbre\n                #'max_depth'\n                #'regressor__n_estimators': [500]\n            }\n\n    forestCV = GridSearchCV(estimator = forest, \n                          param_grid = parameters,\n                          scoring = 'r2',\n                          cv=5,\n                          verbose=0,\n                         return_train_score = True\n                         )\n\n    forestCV.fit(X_train, y_train)\n\n    result = pd.DataFrame(forestCV.cv_results_)\n    display(result)\n\n    new_row = {'Modele':'Random Forest Regressor','Score' : [result[result['rank_test_score']==1]['mean_test_score']]}\n    \n    print(forestCV.best_params_)\n    print('**********')\n    print(forestCV.best_estimator_['regressor'].feature_importances_)\n    \n    return new_row","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.102082Z","iopub.execute_input":"2022-07-06T23:58:05.102585Z","iopub.status.idle":"2022-07-06T23:58:05.117173Z","shell.execute_reply.started":"2022-07-06T23:58:05.102539Z","shell.execute_reply":"2022-07-06T23:58:05.115995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Support Vector Regression\n\ndef support_vector():\n    \n    svr = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('regressor', SVR(kernel=\"linear\"))])\n\n    print('--------------------------------')\n    print(\"3. Support Vector Regression\")\n    print('***')\n    print(\"R2\")\n    print(cross_val_score(svr,X_train, y_train, cv=5, scoring = \"r2\" ))\n    print('***')\n    print(\"-Mse\")\n    print(cross_val_score(svr,X_train, y_train, cv=5, scoring = \"neg_mean_squared_error\"))\n    print('--------------------------------\\n')\n\n\n    parameters = {\n                'regressor__epsilon' : [0.01, 0.1],\n                'regressor__C' : [ 0.1, 1, 10] #parametre de régularisation\n                } \n\n    svm_CV = GridSearchCV(estimator = svr, \n                      param_grid = parameters,\n                      scoring = 'r2',\n                      cv=5,\n                   verbose=2\n                     )\n\n    svm_CV.fit(X_train, y_train)\n\n    result = pd.DataFrame(svm_CV.cv_results_)\n    display(result)\n\n    new_row = {'Modele':'Support Vector Regression','Score' : [result[result['rank_test_score']==1]['mean_test_score']]}\n\n    print(svm_CV.best_params_)\n    print('**********')\n    print(svm_CV.best_estimator_['regressor'].coef_)\n    \n    return new_row","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.118852Z","iopub.execute_input":"2022-07-06T23:58:05.119712Z","iopub.status.idle":"2022-07-06T23:58:05.132345Z","shell.execute_reply.started":"2022-07-06T23:58:05.119636Z","shell.execute_reply":"2022-07-06T23:58:05.131422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Gradient Boosting\n\ndef gradient_boosting():\n\n    gb = Pipeline(steps=[('preprocessor', preprocessor),\n                          ('regressor',GradientBoostingRegressor())]) \n\n    print('--------------------------------')\n    print(\"4. Gradient Boosting\")\n    print('***')\n    print(\"R2\")\n    print(cross_val_score(gb,X_train, y_train, cv=5, scoring = \"r2\" ))\n    print('***')\n    print(\"-Mse\")\n    print(cross_val_score(gb,X_train, y_train, cv=5, scoring = \"neg_mean_squared_error\"))\n    print('--------------------------------\\n')\n\n\n    parameters = {\n                'regressor__n_estimators': [250, 500, 750],\n                'regressor__loss': ['huber'] # Combinaisaon de 'ls', 'lad'\n\n                    }\n    gb_CV = GridSearchCV(estimator = gb, \n                      param_grid = parameters,\n                      scoring = 'r2',\n                      cv=5,\n                   verbose=2\n                     )\n\n    gb_CV.fit(X_train, y_train)\n\n    result = pd.DataFrame(gb_CV.cv_results_)\n    display(result)\n\n    new_row = {'Modele':'Gradient Boosting','Score' : [result[result['rank_test_score']==1]['mean_test_score']]}\n\n    print(gb_CV.best_params_)\n    print('**********')\n    print(gb_CV.best_estimator_['regressor'].feature_importances_)\n    \n    return new_row","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.134279Z","iopub.execute_input":"2022-07-06T23:58:05.134790Z","iopub.status.idle":"2022-07-06T23:58:05.147876Z","shell.execute_reply.started":"2022-07-06T23:58:05.134741Z","shell.execute_reply":"2022-07-06T23:58:05.146835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def models():\n    \n    # Création d'un tableau du meilleur résultat par modèle\n  \n\n    scores = pd.DataFrame()\n    scores = scores.append(baseline(),ignore_index=True)\n    scores = scores.append(elastic_net(),ignore_index=True)\n    scores = scores.append(random_forest(),ignore_index=True)\n    scores = scores.append(support_vector(),ignore_index=True)\n    scores = scores.append(gradient_boosting(),ignore_index=True)\n    \n    print(scores)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.149709Z","iopub.execute_input":"2022-07-06T23:58:05.150123Z","iopub.status.idle":"2022-07-06T23:58:05.163990Z","shell.execute_reply.started":"2022-07-06T23:58:05.150077Z","shell.execute_reply":"2022-07-06T23:58:05.162437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models()","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:58:05.165585Z","iopub.execute_input":"2022-07-06T23:58:05.166578Z","iopub.status.idle":"2022-07-06T23:59:24.707628Z","shell.execute_reply.started":"2022-07-06T23:58:05.166525Z","shell.execute_reply":"2022-07-06T23:59:24.706548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choix du meilleur modele avec les meilleurs paramètres\n\ngb = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor',GradientBoostingRegressor(n_estimators= 250, loss='huber'))]) \n\ngb.fit(X_train,y_train)\ny_pred = gb.predict(X_test)\nr2_score(y_pred,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:59:24.708933Z","iopub.execute_input":"2022-07-06T23:59:24.709226Z","iopub.status.idle":"2022-07-06T23:59:26.135459Z","shell.execute_reply.started":"2022-07-06T23:59:24.709199Z","shell.execute_reply":"2022-07-06T23:59:26.134698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualisation of the top 20 features\n\ndef top_features():\n    \n    # Récuperer les noms de chaque feature\n    onehot_features = gb['preprocessor'].transformers_[1][1]\\\n                       .get_feature_names(categorical_features)\n    feature_names = np.concatenate([numeric_features, onehot_features])\n\n    # Récuperer les coeffcients (ou features importance) de chaque feature\n    coefs = gb.named_steps[\"regressor\"].feature_importances_.flatten()\n\n    # Zipper les coefficients et les noms ensemble et en faire une dataframe\n    zipped = zip(feature_names, coefs)\n    df = pd.DataFrame(zipped, columns=[\"feature\", \"value\"])\n\n    # Trier les features par valeur absolue de leur coefficient\n    df[\"abs_value\"] = df[\"value\"].apply(lambda x: abs(x))\n    df[\"colors\"] = df[\"value\"].apply(lambda x: \"green\" if x > 0 else \"red\")\n    df = df.sort_values(\"abs_value\", ascending=False)\n    \n    # Création et affichage du barplot\n    fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n    sns.barplot(x=\"feature\",\n                y=\"value\",\n                data=df.head(20),\n               palette=df.head(20)[\"colors\"])\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=20)\n    ax.set_title(\"Top 20 Features\", fontsize=25)\n    ax.set_ylabel(\"feature_importances\", fontsize=22)\n    ax.set_xlabel(\"Feature Name\", fontsize=22)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:59:26.136467Z","iopub.execute_input":"2022-07-06T23:59:26.136864Z","iopub.status.idle":"2022-07-06T23:59:26.146699Z","shell.execute_reply.started":"2022-07-06T23:59:26.136836Z","shell.execute_reply":"2022-07-06T23:59:26.145762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_features()","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:59:26.148058Z","iopub.execute_input":"2022-07-06T23:59:26.148402Z","iopub.status.idle":"2022-07-06T23:59:26.641308Z","shell.execute_reply.started":"2022-07-06T23:59:26.148369Z","shell.execute_reply":"2022-07-06T23:59:26.640062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modèles avec Energystarscore\n\ndata['ENERGYSTARScore'] = energy_star_score\ndata = data.dropna()\nprint(data.shape)\n\n\n# Préapration du dataset: Séparation de X,y, création de pipeline avec transformation\n\ny = data[TARGET]\nX = data.copy().drop(['log_GHGEmissions(MetricTonsCO2e)','log_SiteEnergyUseWN(kBtu)'], axis=1)\n\n\n# Séparation et préparation des données\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n\nnumeric_features = ['ENERGYSTARScore','YearBuilt','log_PropertyGFATotal', 'log_LargestPropertyUseTypeGFA',\n                    'log_largest/total', 'log_PropertyGFABuilding(s)','log_PropertyGFAParking']\n\nnumeric_transformer = StandardScaler()\n\ncategorical_features = ['Neighborhood','LargestPropertyUseType']\n\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\n\nprint(\"matrice X_train:\", X_train.shape)\nprint(\"matrice y_train:\", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:59:26.643068Z","iopub.execute_input":"2022-07-06T23:59:26.643515Z","iopub.status.idle":"2022-07-06T23:59:26.666279Z","shell.execute_reply.started":"2022-07-06T23:59:26.643469Z","shell.execute_reply":"2022-07-06T23:59:26.664661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models()","metadata":{"execution":{"iopub.status.busy":"2022-07-06T23:59:26.667609Z","iopub.execute_input":"2022-07-06T23:59:26.667922Z","iopub.status.idle":"2022-07-07T00:00:22.426283Z","shell.execute_reply.started":"2022-07-06T23:59:26.667893Z","shell.execute_reply":"2022-07-07T00:00:22.425241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choix du meilleur modele avec les meilleurs paramètres\n\ngb = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor',GradientBoostingRegressor(n_estimators= 250, loss='huber'))]) \n\ngb.fit(X_train,y_train)\ny_pred = gb.predict(X_test)\nr2_score(y_pred,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:00:22.427728Z","iopub.execute_input":"2022-07-07T00:00:22.428044Z","iopub.status.idle":"2022-07-07T00:00:23.694702Z","shell.execute_reply.started":"2022-07-07T00:00:22.428016Z","shell.execute_reply":"2022-07-07T00:00:23.693552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_features()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:00:23.696234Z","iopub.execute_input":"2022-07-07T00:00:23.696545Z","iopub.status.idle":"2022-07-07T00:00:24.125625Z","shell.execute_reply.started":"2022-07-07T00:00:23.696516Z","shell.execute_reply":"2022-07-07T00:00:24.124292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Emission\n\ndata = pd.read_csv(\"/kaggle/input/datap3/data_p3.csv\", sep=',',low_memory=False)\n\n# Sauvegarde séparée du energy star score\n\nenergy_star_score = data['ENERGYSTARScore']\ndata.drop('ENERGYSTARScore', axis=1, inplace=True)\n\nTARGET = 'log_GHGEmissions(MetricTonsCO2e)'\n\n# Préapration du dataset: Séparation de X,y, création de pipeline avec transformation\n\ny = data[TARGET]\nX = data.copy().drop(['log_GHGEmissions(MetricTonsCO2e)','log_SiteEnergyUseWN(kBtu)'], axis=1)\n\n\n# Séparation et préparation des données\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n\nnumeric_features = ['YearBuilt','log_PropertyGFATotal', 'log_LargestPropertyUseTypeGFA',\n                    'log_largest/total', 'log_PropertyGFABuilding(s)','log_PropertyGFAParking']\n\nnumeric_transformer = StandardScaler()\n\ncategorical_features = ['Neighborhood','LargestPropertyUseType']\n\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\n\nprint(\"matrice X_train:\", X_train.shape)\nprint(\"matrice y_train:\", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:00:24.127099Z","iopub.execute_input":"2022-07-07T00:00:24.127424Z","iopub.status.idle":"2022-07-07T00:00:24.153015Z","shell.execute_reply.started":"2022-07-07T00:00:24.127394Z","shell.execute_reply":"2022-07-07T00:00:24.151938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:00:24.154190Z","iopub.execute_input":"2022-07-07T00:00:24.154533Z","iopub.status.idle":"2022-07-07T00:01:41.707746Z","shell.execute_reply.started":"2022-07-07T00:00:24.154502Z","shell.execute_reply":"2022-07-07T00:01:41.706582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choix du meilleur modele avec les meilleurs paramètres\n\ngb = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor',GradientBoostingRegressor(n_estimators= 250, loss='huber'))]) \n\ngb.fit(X_train,y_train)\ny_pred = gb.predict(X_test)\nr2_score(y_pred,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:01:41.709438Z","iopub.execute_input":"2022-07-07T00:01:41.709923Z","iopub.status.idle":"2022-07-07T00:01:43.190859Z","shell.execute_reply.started":"2022-07-07T00:01:41.709874Z","shell.execute_reply":"2022-07-07T00:01:43.189823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_features()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:01:43.192181Z","iopub.execute_input":"2022-07-07T00:01:43.192448Z","iopub.status.idle":"2022-07-07T00:01:43.640072Z","shell.execute_reply.started":"2022-07-07T00:01:43.192422Z","shell.execute_reply":"2022-07-07T00:01:43.638983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modèles avec Energystarscore\n\ndata['ENERGYSTARScore'] = energy_star_score\ndata = data.dropna()\ndata.shape\n\n\n# Préapration du dataset: Séparation de X,y, création de pipeline avec transformation\n\ny = data[TARGET]\nX = data.copy().drop(['log_GHGEmissions(MetricTonsCO2e)','log_SiteEnergyUseWN(kBtu)'], axis=1)\n\n\n# Séparation et préparation des données\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n\nnumeric_features = ['ENERGYSTARScore','YearBuilt','log_PropertyGFATotal', 'log_LargestPropertyUseTypeGFA',\n                    'log_largest/total', 'log_PropertyGFABuilding(s)','log_PropertyGFAParking']\n\nnumeric_transformer = StandardScaler()\n\ncategorical_features = ['Neighborhood','LargestPropertyUseType']\n\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])\n\nprint(\"matrice X_train:\", X_train.shape)\nprint(\"matrice y_train:\", y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:01:43.641560Z","iopub.execute_input":"2022-07-07T00:01:43.641922Z","iopub.status.idle":"2022-07-07T00:01:43.662218Z","shell.execute_reply.started":"2022-07-07T00:01:43.641890Z","shell.execute_reply":"2022-07-07T00:01:43.661034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:01:43.663339Z","iopub.execute_input":"2022-07-07T00:01:43.663621Z","iopub.status.idle":"2022-07-07T00:02:38.721353Z","shell.execute_reply.started":"2022-07-07T00:01:43.663595Z","shell.execute_reply":"2022-07-07T00:02:38.720353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choix du meilleur modele avec les meilleurs paramètres\n\ngb = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('regressor',GradientBoostingRegressor(n_estimators= 250, loss='huber'))]) \n\ngb.fit(X_train,y_train)\ny_pred = gb.predict(X_test)\nr2_score(y_pred,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:02:38.722589Z","iopub.execute_input":"2022-07-07T00:02:38.722898Z","iopub.status.idle":"2022-07-07T00:02:39.960227Z","shell.execute_reply.started":"2022-07-07T00:02:38.722870Z","shell.execute_reply":"2022-07-07T00:02:39.958814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_features()","metadata":{"execution":{"iopub.status.busy":"2022-07-07T00:02:39.961418Z","iopub.execute_input":"2022-07-07T00:02:39.961774Z","iopub.status.idle":"2022-07-07T00:02:40.406133Z","shell.execute_reply.started":"2022-07-07T00:02:39.961740Z","shell.execute_reply":"2022-07-07T00:02:40.405156Z"},"trusted":true},"execution_count":null,"outputs":[]}]}